{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-27T17:41:45.224536Z","iopub.execute_input":"2023-12-27T17:41:45.225470Z","iopub.status.idle":"2023-12-27T17:41:45.231473Z","shell.execute_reply.started":"2023-12-27T17:41:45.225412Z","shell.execute_reply":"2023-12-27T17:41:45.230473Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport matplotlib.image as implt\nimport pandas as pd\nimport  glob\nimport random\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:58:55.991387Z","iopub.execute_input":"2023-12-27T17:58:55.991776Z","iopub.status.idle":"2023-12-27T17:59:00.178614Z","shell.execute_reply.started":"2023-12-27T17:58:55.991747Z","shell.execute_reply":"2023-12-27T17:59:00.177832Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.rmdir('.virtual_documents') ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.275490Z","iopub.execute_input":"2023-12-27T17:41:45.275782Z","iopub.status.idle":"2023-12-27T17:41:45.603405Z","shell.execute_reply.started":"2023-12-27T17:41:45.275759Z","shell.execute_reply":"2023-12-27T17:41:45.600931Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.virtual_documents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.virtual_documents'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '.virtual_documents'","output_type":"error"}]},{"cell_type":"code","source":"class Generator(nn.Module):\n    '''\n    Generator Class\n    Values:\n        z_dim: the dimension of the noise vector, a scalar\n        im_chan: the number of channels of the output image, a scalar\n              (MNIST is black-and-white, so 1 channel is your default)\n        hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, input_dim=171, im_chan=3, hidden_dim=64):\n        super(Generator, self).__init__()\n        self.input_dim = input_dim\n        # Build the neural network\n        self.gen = nn.Sequential(\n            self.make_gen_block(input_dim, hidden_dim * 4),\n            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n            self.make_gen_block(hidden_dim * 2, hidden_dim),\n            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n        )\n\n    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n        '''\n        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n        Parameters:\n            input_channels: how many channels the input feature representation has\n            output_channels: how many channels the output feature representation should have\n            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n            stride: the stride of the convolution\n            final_layer: a boolean, true if it is the final layer and false otherwise \n                      (affects activation and batchnorm)\n        '''\n        if not final_layer:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.ReLU(inplace=True),\n            )\n        else:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.Tanh(),\n            )\n\n    def forward(self, noise):\n        '''\n        Function for completing a forward pass of the generator: Given a noise tensor,\n        returns generated images.\n        Parameters:\n            noise: a noise tensor with dimensions (n_samples, z_dim)\n        '''\n        x = noise.view(len(noise), self.input_dim, 1, 1)\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.604327Z","iopub.status.idle":"2023-12-27T17:41:45.604694Z","shell.execute_reply.started":"2023-12-27T17:41:45.604526Z","shell.execute_reply":"2023-12-27T17:41:45.604543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_one_hot_labels(labels, n_classes=35):\n    return F.one_hot(labels, n_classes)\n\ndef combine_vectors(x, y):\n    return torch.cat((x.float(), y.float()), 1)\n\ndef get_input_dimensions(z_dim, img_shape=(3, 64, 64), n_classes=35):\n    gen_input_dim = z_dim + n_classes\n    disc_input_dim = img_shape[0] + n_classes\n    \n    return gen_input_dim, disc_input_dim\n\ndef get_noise(n_samples, z_dim, device='cpu'):\n    '''\n    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n    creates a tensor of that shape filled with random numbers from the normal distribution.\n    Parameters:\n      n_samples: the number of samples to generate, a scalar\n      z_dim: the dimension of the noise vector, a scalar\n      device: the device type\n    '''\n    return torch.randn(n_samples, z_dim, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.605841Z","iopub.status.idle":"2023-12-27T17:41:45.606174Z","shell.execute_reply.started":"2023-12-27T17:41:45.606006Z","shell.execute_reply":"2023-12-27T17:41:45.606028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z_dim = 128\ngen_in_dim, _ = get_input_dimensions(z_dim)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.607339Z","iopub.status.idle":"2023-12-27T17:41:45.607688Z","shell.execute_reply.started":"2023-12-27T17:41:45.607527Z","shell.execute_reply":"2023-12-27T17:41:45.607542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device='cuda'\ngen = Generator(input_dim=gen_in_dim).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.609199Z","iopub.status.idle":"2023-12-27T17:41:45.609563Z","shell.execute_reply.started":"2023-12-27T17:41:45.609367Z","shell.execute_reply":"2023-12-27T17:41:45.609383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_tensor_images(image_tensor, num_images=25, size=(1, 64, 64)):\n    '''\n    Function for visualizing images: Given a tensor of images, number of images, and\n    size per image, plots and prints the images in an uniform grid.\n    '''\n    image_tensor = (image_tensor + 1) / 2\n    image_unflat = image_tensor.detach().cpu()\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()\n    \ndef make_grad_hook():\n    '''\n    Function to keep track of gradients for visualization purposes, \n    which fills the grads list when using model.apply(grad_hook).\n    '''\n    grads = []\n    def grad_hook(m):\n        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n            grads.append(m.weight.grad)\n    return grads, grad_hook\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.610833Z","iopub.status.idle":"2023-12-27T17:41:45.611191Z","shell.execute_reply.started":"2023-12-27T17:41:45.610997Z","shell.execute_reply":"2023-12-27T17:41:45.611019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes= sorted(os.listdir('/kaggle/input/lisadataset/croppedimages'))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.612391Z","iopub.status.idle":"2023-12-27T17:41:45.612763Z","shell.execute_reply.started":"2023-12-27T17:41:45.612586Z","shell.execute_reply":"2023-12-27T17:41:45.612602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_weights = torch.load('/kaggle/input/notebookdfef0d9731/models/generator-gtsrb.pth')\ngen.load_state_dict(gen_weights)\ngen.eval()\ncount = 2800*35\n\nlabels=[]\nfor i in range(35):\n    labels += [i]*2800\n\n\ntest_noise = get_noise(count, z_dim, device)\ntest_label = torch.tensor(labels)\ntest_OH_label = get_one_hot_labels(test_label.to(device))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.613911Z","iopub.status.idle":"2023-12-27T17:41:45.614298Z","shell.execute_reply.started":"2023-12-27T17:41:45.614099Z","shell.execute_reply":"2023-12-27T17:41:45.614117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_noise_and_label = combine_vectors(test_noise, test_OH_label)\ntest_image_fake = gen(test_noise_and_label)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.616260Z","iopub.status.idle":"2023-12-27T17:41:45.616606Z","shell.execute_reply.started":"2023-12-27T17:41:45.616413Z","shell.execute_reply":"2023-12-27T17:41:45.616446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in classes:\n    os.mkdir(i)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.618024Z","iopub.status.idle":"2023-12-27T17:41:45.618401Z","shell.execute_reply.started":"2023-12-27T17:41:45.618226Z","shell.execute_reply":"2023-12-27T17:41:45.618242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_nofilter(img):\n    return img\n\ndef add_highBeam(img):\n    \n    # Define gamma and gain\n    gamma = 0.7\n    gain = 1\n\n    # Apply gamma correction\n    x_transformed = gain * torch.pow((img), gamma)\n\n    return transforms.functional.adjust_gamma(img, 0.1,1)\n\ndef add_fog(img):\n    # Define fog intensity and contrast reduction\n    fog_intensity = 0.2  # adjust this value to control fog density\n    contrast_reduction = 0.5  # adjust this value to control contrast\n\n    # Create a fog layer\n    fog_layer = torch.rand_like(img) * fog_intensity\n\n    # Reduce contrast and sharpness\n    img_foggy = torch.pow(img, contrast_reduction)\n\n    # Combine the fog layer and the image\n    img_foggy = img_foggy * (1 - fog_layer) + fog_layer\n    img_foggy = img_foggy*0.35\n    \n    return img_foggy\n\ndef add_snow(img_batch):\n    img_batch = img_batch[None,:]\n    imgcopy = img_batch.clone()\n    num_images, _, row, col = img_batch.shape\n    for i in range(num_images):\n        number_of_pixels = random.randint(15, 25)\n        for _ in range(number_of_pixels): \n            y_coord = random.randint(0, row - 1)\n            x_coord = random.randint(0, col - 1) \n            imgcopy[i, :, y_coord, x_coord] = 1.0\n    return imgcopy[0]\n\ndef add_rain(img_batch):\n    img_batch = img_batch[None,:]\n    imgcopy = img_batch.clone()\n    num_images, _, row, col = img_batch.shape\n    for i in range(num_images):\n        number_of_pixels = random.randint(15, 25)\n        for _ in range(number_of_pixels): \n            y_coord = random.randint(0, row - 2)\n            x_coord = random.randint(0, col - 1) \n            imgcopy[i, :, y_coord, x_coord] = 128/255\n            if random.randint(0, 1):\n                imgcopy[i, :, y_coord+1, x_coord] = 128/255\n                \n    return imgcopy[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.619944Z","iopub.status.idle":"2023-12-27T17:41:45.620384Z","shell.execute_reply.started":"2023-12-27T17:41:45.620157Z","shell.execute_reply":"2023-12-27T17:41:45.620178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_functions = [add_nofilter, add_snow, add_rain, add_highBeam, add_fog]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.621991Z","iopub.status.idle":"2023-12-27T17:41:45.622433Z","shell.execute_reply.started":"2023-12-27T17:41:45.622196Z","shell.execute_reply":"2023-12-27T17:41:45.622217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, i in enumerate(test_image_fake):\n    random_function = random.sample(list_of_functions,1)[0]\n    i = (i+1)/2\n    numpy_image = random_function(i).to('cpu').detach().permute(1,2,0).numpy()\n    numpy_image = (numpy_image-np.min(numpy_image))/(np.max(numpy_image) - np.min(numpy_image))\n    plt.imsave(os.path.join('/kaggle/working/',classes[index//2800],str(index%2800)) + '.jpg', numpy_image)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.623714Z","iopub.status.idle":"2023-12-27T17:41:45.624142Z","shell.execute_reply.started":"2023-12-27T17:41:45.623920Z","shell.execute_reply":"2023-12-27T17:41:45.623941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, i in enumerate(test_image_fake):\n    random_function = random.sample(list_of_functions,1)[0]\n    i = (i+1)/2\n    numpy_image = random_function(i).to('cpu').detach().permute(1,2,0).numpy()\n    numpy_image = (numpy_image-np.min(numpy_image))/(np.max(numpy_image) - np.min(numpy_image))\n    plt.imsave(os.path.join('/kaggle/working/',classes[index//2800],str(2800+index%2800)) + '.jpg', numpy_image)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.625383Z","iopub.status.idle":"2023-12-27T17:41:45.625840Z","shell.execute_reply.started":"2023-12-27T17:41:45.625617Z","shell.execute_reply":"2023-12-27T17:41:45.625638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for className in classes:\n    classPath = os.path.join('/kaggle/input/lisadataset/croppedimages',className)\n    for index, imageName in enumerate(os.listdir(classPath)):\n        random_function = random.sample(list_of_functions,1)[0]\n        img = cv2.imread(os.path.join(classPath, imageName))\n        filtered_image = random_function(torch.tensor(img/255., device='cpu').permute(2,0,1)).permute(1,2,0).numpy()\n        filtered_image = (filtered_image-np.min(filtered_image))/(np.max(filtered_image) - np.min(filtered_image))\n        outputPath = os.path.join('/kaggle/working/', className, str(5600+index)) + '.jpg'\n        plt.imsave(outputPath, filtered_image)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.626760Z","iopub.status.idle":"2023-12-27T17:41:45.627208Z","shell.execute_reply.started":"2023-12-27T17:41:45.626962Z","shell.execute_reply":"2023-12-27T17:41:45.626983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/generated_images', 'zip', '/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.628291Z","iopub.status.idle":"2023-12-27T17:41:45.628755Z","shell.execute_reply.started":"2023-12-27T17:41:45.628516Z","shell.execute_reply":"2023-12-27T17:41:45.628545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=0\nfor i in os.listdir('/kaggle/working/'):\n    s += len(os.listdir(os.path.join('/kaggle/working/', i)))\ns","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:41:45.629855Z","iopub.status.idle":"2023-12-27T17:41:45.630179Z","shell.execute_reply.started":"2023-12-27T17:41:45.630019Z","shell.execute_reply":"2023-12-27T17:41:45.630034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **VIT** ","metadata":{}},{"cell_type":"code","source":"# Install necessary modules\n!pip install torch-summary\n!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:00:40.206666Z","iopub.execute_input":"2023-12-27T18:00:40.207251Z","iopub.status.idle":"2023-12-27T18:01:04.885894Z","shell.execute_reply.started":"2023-12-27T18:00:40.207211Z","shell.execute_reply":"2023-12-27T18:01:04.884740Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.2.1)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.24.3)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.10.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import Dependencies\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport random\nfrom glob import glob\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport math\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport torch\nfrom torchsummary import summary\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom typing import Dict, List, Tuple\nfrom tqdm import tqdm\nfrom torchmetrics import Accuracy, F1Score, Recall, Precision","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:04.887953Z","iopub.execute_input":"2023-12-27T18:01:04.888265Z","iopub.status.idle":"2023-12-27T18:01:07.861286Z","shell.execute_reply.started":"2023-12-27T18:01:04.888238Z","shell.execute_reply":"2023-12-27T18:01:07.860340Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"os.rmdir('.virtual_documents') ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:07.862473Z","iopub.execute_input":"2023-12-27T18:01:07.862885Z","iopub.status.idle":"2023-12-27T18:01:07.867431Z","shell.execute_reply.started":"2023-12-27T18:01:07.862859Z","shell.execute_reply":"2023-12-27T18:01:07.866353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# List of class names as considered by data loader\nx = sorted(os.listdir('/kaggle/working/'))\n# Convert list of class names into dictionary\nclasses = {key: value for key, value in enumerate(x)}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:07.870022Z","iopub.execute_input":"2023-12-27T18:01:07.870396Z","iopub.status.idle":"2023-12-27T18:01:07.879161Z","shell.execute_reply.started":"2023-12-27T18:01:07.870365Z","shell.execute_reply":"2023-12-27T18:01:07.878493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define Image Transforms\ntransform = transforms.Compose([\n    transforms.Resize((81, 81)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create Dataset of entire data\nfull_dataset = datasets.ImageFolder(root='/kaggle/working', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:07.880412Z","iopub.execute_input":"2023-12-27T18:01:07.880803Z","iopub.status.idle":"2023-12-27T18:01:08.763668Z","shell.execute_reply.started":"2023-12-27T18:01:07.880741Z","shell.execute_reply":"2023-12-27T18:01:08.762893Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(full_dataset)) # Split data count into training and validation splits in the ratio 80% to 20%\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size]) # Split the data","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.764792Z","iopub.execute_input":"2023-12-27T18:01:08.765080Z","iopub.status.idle":"2023-12-27T18:01:08.797047Z","shell.execute_reply.started":"2023-12-27T18:01:08.765054Z","shell.execute_reply":"2023-12-27T18:01:08.796390Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"batch_size = 128  #Set batch size\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4) # Create train dataloader\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4) # Create valiation dataloader","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.798110Z","iopub.execute_input":"2023-12-27T18:01:08.798350Z","iopub.status.idle":"2023-12-27T18:01:08.803245Z","shell.execute_reply.started":"2023-12-27T18:01:08.798328Z","shell.execute_reply":"2023-12-27T18:01:08.802327Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Patch Embedding Class\nclass PatchEmbedding(nn.Module):\n    '''\n    Creates Patch Embedding layer to patch the input features from Xception model backbone, and flattens it.\n    '''\n    def __init__(self, \n                 in_channels:int=3,\n                 patch_size:int=3,\n                 embedding_dim:int=3*3*3):\n        super().__init__()\n        \n        #  Layer to turn features into patches\n        self.patcher = nn.Conv2d(in_channels=in_channels,\n                                 out_channels=embedding_dim,\n                                 kernel_size=patch_size,\n                                 stride=patch_size,\n                                 padding=0)\n\n        #  Layer to flatten the patch feature maps into a single dimension\n        self.flatten = nn.Flatten(start_dim=2, end_dim=3)\n        \n        \n    def forward(self, x):\n        \n        x_patched = self.patcher(x)\n        x_flattened = self.flatten(x_patched) \n        \n        return x_flattened.permute(0, 2, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.804616Z","iopub.execute_input":"2023-12-27T18:01:08.804947Z","iopub.status.idle":"2023-12-27T18:01:08.817503Z","shell.execute_reply.started":"2023-12-27T18:01:08.804919Z","shell.execute_reply":"2023-12-27T18:01:08.816552Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Multi-head Self Attention Class\nclass MultiheadSelfAttentionBlock(nn.Module):\n    \"\"\"\n    Creates a multi-head self-attention block.\n    \"\"\"\n\n    def __init__(self,\n                 embedding_dim:int=3*3*3, \n                 num_heads:int=3, \n                 attn_dropout:float=0): \n        super().__init__()\n \n        # Layer Normalization\n        self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n        \n        # Multi-Head Attention layer\n        self.multihead_attn = nn.MultiheadAttention(embed_dim=embedding_dim,\n                                                    num_heads=num_heads,\n                                                    dropout=attn_dropout,\n                                                    batch_first=True)\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        attn_output, _ = self.multihead_attn(query=x, \n                                             key=x,\n                                             value=x,\n                                             need_weights=False)\n        return attn_output","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.818551Z","iopub.execute_input":"2023-12-27T18:01:08.818789Z","iopub.status.idle":"2023-12-27T18:01:08.828028Z","shell.execute_reply.started":"2023-12-27T18:01:08.818767Z","shell.execute_reply":"2023-12-27T18:01:08.827224Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# MLP (Multilayer Perceptron) Class\nclass MLPBlock(nn.Module):\n    \"\"\"Creates a Layer Normalized Multilayer Perceptron block.\"\"\"\n    def __init__(self,\n                 embedding_dim:int=3*3*3,\n                 mlp_size:int=3072,\n                 dropout:float=0.1):\n        super().__init__()\n        \n        # Norm layer \n        self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n        \n        # MLP layer\n        self.mlp = nn.Sequential(\n            nn.Linear(in_features=embedding_dim,\n                      out_features=mlp_size),\n            nn.GELU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(in_features=mlp_size,\n                      out_features=embedding_dim), \n            nn.Dropout(p=dropout)\n        )\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        x = self.mlp(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.831583Z","iopub.execute_input":"2023-12-27T18:01:08.831948Z","iopub.status.idle":"2023-12-27T18:01:08.842324Z","shell.execute_reply.started":"2023-12-27T18:01:08.831923Z","shell.execute_reply":"2023-12-27T18:01:08.841603Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Transformer Encoder Class\nclass TransformerEncoderBlock(nn.Module):\n    \"\"\"\n    Creates a Transformer Encoder block.\n    \"\"\"\n    \n    def __init__(self,\n                 embedding_dim:int=3*3*3,\n                 num_heads:int=3, \n                 mlp_size:int=3072,\n                 mlp_dropout:float=0.1, \n                 attn_dropout:float=0): \n        super().__init__()\n\n        # Multi-head Self Attention Block\n        self.msa_block = MultiheadSelfAttentionBlock(embedding_dim=embedding_dim,\n                                                     num_heads=num_heads,\n                                                     attn_dropout=attn_dropout)\n        \n        # MLP Block\n        self.mlp_block =  MLPBlock(embedding_dim=embedding_dim,\n                                   mlp_size=mlp_size,\n                                   dropout=mlp_dropout)\n\n    def forward(self, x):\n        \n        x =  self.msa_block(x) + x \n        x = self.mlp_block(x) + x \n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.843605Z","iopub.execute_input":"2023-12-27T18:01:08.844281Z","iopub.status.idle":"2023-12-27T18:01:08.854286Z","shell.execute_reply.started":"2023-12-27T18:01:08.844247Z","shell.execute_reply":"2023-12-27T18:01:08.853564Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class SeparableConv2d(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n        super(SeparableConv2d,self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.pointwise(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.855166Z","iopub.execute_input":"2023-12-27T18:01:08.855411Z","iopub.status.idle":"2023-12-27T18:01:08.868782Z","shell.execute_reply.started":"2023-12-27T18:01:08.855389Z","shell.execute_reply":"2023-12-27T18:01:08.867983Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Xception Block Class\nclass Block(nn.Module):\n    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n        super(Block, self).__init__()\n\n        if out_filters != in_filters or strides!=1:\n            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n            self.skipbn = nn.BatchNorm2d(out_filters)\n        else:\n            self.skip=None\n        \n        self.relu = nn.ReLU(inplace=True)\n        rep=[]\n\n        filters=in_filters\n        if grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n            filters = out_filters\n\n        for i in range(reps-1):\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(filters))\n        \n        if not grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n\n        if not start_with_relu:\n            rep = rep[1:]\n        else:\n            rep[0] = nn.ReLU(inplace=False)\n\n        if strides != 1:\n            rep.append(nn.MaxPool2d(3,strides,1))\n        self.rep = nn.Sequential(*rep)\n\n    def forward(self,inp):\n        x = self.rep(inp)\n\n        if self.skip is not None:\n            skip = self.skip(inp)\n            skip = self.skipbn(skip)\n        else:\n            skip = inp\n\n        x+=skip\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.869893Z","iopub.execute_input":"2023-12-27T18:01:08.870380Z","iopub.status.idle":"2023-12-27T18:01:08.883124Z","shell.execute_reply.started":"2023-12-27T18:01:08.870348Z","shell.execute_reply":"2023-12-27T18:01:08.882263Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Xception(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(Xception, self).__init__()\n        \n        self.num_classes = num_classes\n\n        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n        self.bn2 = nn.BatchNorm2d(64)\n\n        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n\n        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n\n        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n        self.bn3 = nn.BatchNorm2d(1536)\n\n        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n        self.bn4 = nn.BatchNorm2d(2048)\n        \n        self.upsample = nn.Upsample((2, 2))\n        self.convtranspose = nn.ConvTranspose2d(2048, 3, kernel_size=5, stride=4)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n        x = self.block8(x)\n        x = self.block9(x)\n        x = self.block10(x)\n        x = self.block11(x)\n        x = self.block12(x)\n        \n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n        \n        x = self.conv4(x)\n        x = self.bn4(x)\n        x = self.relu(x)\n        \n        x = self.upsample(x)\n        x = self.upsample(x)\n        x = self.convtranspose(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.884316Z","iopub.execute_input":"2023-12-27T18:01:08.884644Z","iopub.status.idle":"2023-12-27T18:01:08.903568Z","shell.execute_reply.started":"2023-12-27T18:01:08.884619Z","shell.execute_reply":"2023-12-27T18:01:08.902706Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class ViT(nn.Module):\n    \"\"\"Creates a Vision Transformer architecture with Xception Model backbone.\"\"\"\n    # 2. Initialize the class with hyperparameters from Table 1 and Table 3\n    def __init__(self,\n                 img_size:int=9, # Feature map resolution\n                 in_channels:int=3, # Number of channels in input feature map\n                 patch_size:int=3, # Patch size\n                 num_transformer_layers:int=12,\n                 embedding_dim:int=3*3*3,\n                 mlp_size:int=3072, # MLP size\n                 num_heads:int=3,\n                 attn_dropout:float=0, # Dropout for Attention Projection\n                 mlp_dropout:float=0.1, # Dropout for MLP layers \n                 embedding_dropout:float=0.1, # Dropout for Patch and Position Embeddings\n                 num_classes:int= 35): # Total number of traffic sign classes \n        \n        super().__init__()\n        \n        self.xception_model = Xception()\n        \n        # Calculate Number of Patches ((height * width)/(patch^2))\n        self.num_patches = (img_size * img_size) // patch_size**2\n                 \n        # Learnable Class Embedding\n        self.class_embedding = nn.Parameter(data=torch.randn(1, 1, embedding_dim),\n                                            requires_grad=True)\n        \n        # Learnable Position Embedding\n        self.position_embedding = nn.Parameter(data=torch.randn(1, self.num_patches+1, embedding_dim),\n                                               requires_grad=True)\n                \n        # Embedding Dropout\n        self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n        \n        # Patch Embedding Layer\n        self.patch_embedding = PatchEmbedding(in_channels=in_channels,\n                                              patch_size=patch_size,\n                                              embedding_dim=embedding_dim)\n        \n        # Create Transformer Encoder Blocks\n        self.transformer_encoder = nn.Sequential(*[TransformerEncoderBlock(embedding_dim=embedding_dim,\n                                                                            num_heads=num_heads,\n                                                                            mlp_size=mlp_size,\n                                                                            mlp_dropout=mlp_dropout) for _ in range(num_transformer_layers)])\n       \n        # Create Classifier Head\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(normalized_shape=embedding_dim),\n            nn.Linear(in_features=embedding_dim, \n                      out_features=num_classes)\n        )\n        \n    def forward(self, x):\n        \n        x = self.xception_model(x)\n        \n        # Get Batch size\n        batch_size = x.shape[0]\n\n        class_token = self.class_embedding.expand(batch_size, -1, -1)\n\n        x = self.patch_embedding(x)\n        x = torch.cat((class_token, x), dim=1)\n        x = self.position_embedding + x\n\n        x = self.embedding_dropout(x)\n        x = self.transformer_encoder(x)\n        \n        x = self.classifier(x[:, 0])\n        \n        return x   ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.904729Z","iopub.execute_input":"2023-12-27T18:01:08.905044Z","iopub.status.idle":"2023-12-27T18:01:08.918530Z","shell.execute_reply.started":"2023-12-27T18:01:08.905019Z","shell.execute_reply":"2023-12-27T18:01:08.917525Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device,\n               train_acc_metric,\n               train_f1_metric,\n               train_recall_metric,\n               train_prec_metric) -> Tuple[float, float, float, float, float]:\n    \n    model.train()\n    \n    train_loss, acc, f1, recall, precision = 0, 0, 0, 0, 0\n\n    for batch, (X, y) in tqdm(enumerate(dataloader)):\n        X, y = X.to(device), y.to(device)\n\n        # Forward pass\n        y_pred = model(X)\n\n        # Calculate and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Backward pass\n        loss.backward()\n\n        # Optimizer step\n        optimizer.step()\n\n        # Update metrics\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        acc += train_acc_metric(y_pred_class, y)\n        f1 += train_f1_metric(y_pred_class, y)\n        recall += train_recall_metric(y_pred_class, y)\n        precision += train_prec_metric(y_pred_class, y)\n\n    # Compute metrics\n    train_loss = train_loss / len(dataloader)\n    train_acc = acc / len(dataloader)\n    train_f1 = f1 / len(dataloader)\n    train_rec = recall / len(dataloader)\n    train_precision = precision / len(dataloader)\n\n    return train_loss, train_acc, train_f1, train_rec, train_precision","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.919962Z","iopub.execute_input":"2023-12-27T18:01:08.920256Z","iopub.status.idle":"2023-12-27T18:01:08.932418Z","shell.execute_reply.started":"2023-12-27T18:01:08.920231Z","shell.execute_reply":"2023-12-27T18:01:08.931696Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module, \n              device: torch.device,\n              test_f1_metric,\n              test_recall_metric,\n              test_acc_metric,\n              test_prec_metric) -> Tuple[float, float, float, float, float]:\n    \n    model.eval()\n\n    test_loss, acc, f1, recall, precision = 0, 0, 0, 0, 0\n\n    with torch.no_grad():\n        for batch, (X, y) in tqdm(enumerate(dataloader)):\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            y_pred = model(X)\n\n            # Calculate and accumulate loss\n            loss = loss_fn(y_pred, y)\n            test_loss += loss.item() \n\n            # Update metrics\n            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n            acc += test_acc_metric(y_pred_class, y)\n            f1 += test_f1_metric(y_pred_class, y)\n            recall += test_recall_metric(y_pred_class, y)\n            precision += test_prec_metric(y_pred_class, y)\n\n    # Compute metrics\n    test_loss = test_loss / len(dataloader)\n    test_acc = acc / len(dataloader)\n    test_f1 = f1 / len(dataloader)\n    test_rec = recall / len(dataloader)\n    test_precision = precision / len(dataloader)\n\n    return test_loss, test_acc, test_f1, test_rec, test_precision","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.933413Z","iopub.execute_input":"2023-12-27T18:01:08.933702Z","iopub.status.idle":"2023-12-27T18:01:08.946979Z","shell.execute_reply.started":"2023-12-27T18:01:08.933679Z","shell.execute_reply":"2023-12-27T18:01:08.946102Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n\n    # Initialize metrics\n    train_acc_metric = Accuracy(task=\"multiclass\", num_classes=35).to(device)\n    train_f1_metric = F1Score(task=\"multiclass\", average='macro', num_classes=35).to(device)\n    train_recall_metric = Recall(task=\"multiclass\", average='macro', num_classes=35).to(device)\n    train_prec_metric = Precision(task=\"multiclass\", average='macro', num_classes=35).to(device)\n\n    test_acc_metric = Accuracy(task=\"multiclass\", num_classes=35).to(device)\n    test_f1_metric = F1Score(task=\"multiclass\", average='macro', num_classes=35).to(device)\n    test_recall_metric = Recall(task=\"multiclass\", average='macro', num_classes=35).to(device)\n    test_prec_metric = Precision(task=\"multiclass\", average='macro', num_classes=35).to(device)\n\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"train_f1_score\": [],\n               \"train_recall\": [],\n               \"train_precision\": [],\n               \"val_loss\": [],\n               \"val_acc\": [],\n               \"val_f1_score\": [],\n               \"val_recall\": [],\n               \"val_precision\": []\n    }\n    \n    model.to(device)\n\n    for epoch in range(epochs):\n       \n        \n        train_loss, train_acc, train_f1_score, train_recall, train_precision = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device,\n                                          train_acc_metric=train_acc_metric,\n                                          train_f1_metric=train_f1_metric,\n                                          train_recall_metric=train_recall_metric,\n                                          train_prec_metric=train_prec_metric)\n                                          \n        test_loss, test_acc, test_f1_score, test_recall, test_precision = test_step(model=model,\n                                  dataloader=test_dataloader,\n                                  loss_fn=loss_fn,\n                                  device=device,\n                                  test_acc_metric=test_acc_metric,\n                                  test_f1_metric=test_f1_metric,\n                                  test_recall_metric=test_recall_metric,\n                                  test_prec_metric=test_prec_metric)\n\n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"train_F1_score: {train_f1_score:.4f} | \"\n          f\"train_recall: {train_recall:.4f} | \"\n          f\"train_precision: {train_precision:.4f} | \"\n          f\"val_loss: {test_loss:.4f} | \"\n          f\"val_acc: {test_acc:.4f} | \"\n          f\"val_F1_score: {test_f1_score:.4f} | \"\n          f\"val_recall: {test_recall:.4f} | \"\n          f\"val_precision: {test_precision:.4f}\"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"train_f1_score\"].append(train_f1_score)\n        results[\"train_recall\"].append(train_recall)\n        results[\"train_precision\"].append(train_precision)\n        results[\"val_loss\"].append(test_loss)\n        results[\"val_acc\"].append(test_acc)\n        results[\"val_f1_score\"].append(test_f1_score)\n        results[\"val_recall\"].append(test_recall)\n        results[\"val_precision\"].append(test_precision)\n        if epoch in [31, 63, 95,127]:\n            torch.save(\n                obj=model.state_dict(),\n                f=f\"/kaggle/working/epoch_{epoch+1}.pth\"\n            )\n\n    return results\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:01:08.948106Z","iopub.execute_input":"2023-12-27T18:01:08.948412Z","iopub.status.idle":"2023-12-27T18:01:08.968190Z","shell.execute_reply.started":"2023-12-27T18:01:08.948388Z","shell.execute_reply":"2023-12-27T18:01:08.967417Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Initialize Model\nmodel = ViT()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:05:05.967696Z","iopub.execute_input":"2023-12-27T18:05:05.968051Z","iopub.status.idle":"2023-12-27T18:05:06.326813Z","shell.execute_reply.started":"2023-12-27T18:05:05.968022Z","shell.execute_reply":"2023-12-27T18:05:06.325948Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizer, loss and device to train on\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\nloss = nn.CrossEntropyLoss()\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:05:07.606990Z","iopub.execute_input":"2023-12-27T18:05:07.607348Z","iopub.status.idle":"2023-12-27T18:05:07.614750Z","shell.execute_reply.started":"2023-12-27T18:05:07.607318Z","shell.execute_reply":"2023-12-27T18:05:07.613704Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train the model and store the results in \"history\" variable\nhistory = train(model=model,\n       train_dataloader=train_dataloader,\n       test_dataloader=val_dataloader,\n       optimizer=optimizer,\n       loss_fn=loss,\n       epochs=128,\n       device=device)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T18:05:08.875067Z","iopub.execute_input":"2023-12-27T18:05:08.875388Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"1243it [04:53,  4.24it/s]\n311it [00:20, 15.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 | train_loss: 0.3561 | train_acc: 0.9194 | train_F1_score: 0.9070 | train_recall: 0.9176 | train_precision: 0.9116 | val_loss: 0.2517 | val_acc: 0.9466 | val_F1_score: 0.9350 | val_recall: 0.9439 | val_precision: 0.9461\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.27it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2 | train_loss: 0.0408 | train_acc: 0.9919 | train_F1_score: 0.9900 | train_recall: 0.9916 | train_precision: 0.9912 | val_loss: 0.0463 | val_acc: 0.9900 | val_F1_score: 0.9881 | val_recall: 0.9899 | val_precision: 0.9896\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.44it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3 | train_loss: 0.0281 | train_acc: 0.9941 | train_F1_score: 0.9926 | train_recall: 0.9937 | train_precision: 0.9934 | val_loss: 0.0854 | val_acc: 0.9712 | val_F1_score: 0.9621 | val_recall: 0.9692 | val_precision: 0.9663\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.45it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4 | train_loss: 0.0204 | train_acc: 0.9957 | train_F1_score: 0.9945 | train_recall: 0.9953 | train_precision: 0.9952 | val_loss: 0.0102 | val_acc: 0.9977 | val_F1_score: 0.9973 | val_recall: 0.9976 | val_precision: 0.9976\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.40it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 | train_loss: 0.0156 | train_acc: 0.9963 | train_F1_score: 0.9954 | train_recall: 0.9961 | train_precision: 0.9958 | val_loss: 0.0139 | val_acc: 0.9973 | val_F1_score: 0.9967 | val_recall: 0.9971 | val_precision: 0.9971\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6 | train_loss: 0.0145 | train_acc: 0.9967 | train_F1_score: 0.9958 | train_recall: 0.9964 | train_precision: 0.9964 | val_loss: 0.0134 | val_acc: 0.9971 | val_F1_score: 0.9959 | val_recall: 0.9963 | val_precision: 0.9964\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.03it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 7 | train_loss: 0.0125 | train_acc: 0.9973 | train_F1_score: 0.9966 | train_recall: 0.9972 | train_precision: 0.9970 | val_loss: 0.0138 | val_acc: 0.9966 | val_F1_score: 0.9958 | val_recall: 0.9964 | val_precision: 0.9962\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.21it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 8 | train_loss: 0.0104 | train_acc: 0.9976 | train_F1_score: 0.9968 | train_recall: 0.9973 | train_precision: 0.9971 | val_loss: 0.0102 | val_acc: 0.9977 | val_F1_score: 0.9972 | val_recall: 0.9975 | val_precision: 0.9977\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.42it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 9 | train_loss: 0.0104 | train_acc: 0.9976 | train_F1_score: 0.9970 | train_recall: 0.9975 | train_precision: 0.9973 | val_loss: 0.0200 | val_acc: 0.9956 | val_F1_score: 0.9944 | val_recall: 0.9952 | val_precision: 0.9949\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.43it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | train_loss: 0.0077 | train_acc: 0.9982 | train_F1_score: 0.9977 | train_recall: 0.9981 | train_precision: 0.9980 | val_loss: 0.0114 | val_acc: 0.9974 | val_F1_score: 0.9970 | val_recall: 0.9971 | val_precision: 0.9976\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.47it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 | train_loss: 0.0066 | train_acc: 0.9983 | train_F1_score: 0.9979 | train_recall: 0.9982 | train_precision: 0.9980 | val_loss: 0.0136 | val_acc: 0.9973 | val_F1_score: 0.9967 | val_recall: 0.9971 | val_precision: 0.9972\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 | train_loss: 0.0059 | train_acc: 0.9987 | train_F1_score: 0.9984 | train_recall: 0.9987 | train_precision: 0.9986 | val_loss: 0.0081 | val_acc: 0.9983 | val_F1_score: 0.9980 | val_recall: 0.9983 | val_precision: 0.9983\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.54it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 13 | train_loss: 0.0057 | train_acc: 0.9987 | train_F1_score: 0.9983 | train_recall: 0.9986 | train_precision: 0.9984 | val_loss: 0.0083 | val_acc: 0.9977 | val_F1_score: 0.9972 | val_recall: 0.9975 | val_precision: 0.9976\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.48it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 14 | train_loss: 0.0042 | train_acc: 0.9989 | train_F1_score: 0.9987 | train_recall: 0.9990 | train_precision: 0.9988 | val_loss: 0.0126 | val_acc: 0.9975 | val_F1_score: 0.9968 | val_recall: 0.9971 | val_precision: 0.9971\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.46it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 15 | train_loss: 0.0068 | train_acc: 0.9985 | train_F1_score: 0.9981 | train_recall: 0.9983 | train_precision: 0.9983 | val_loss: 0.0058 | val_acc: 0.9987 | val_F1_score: 0.9985 | val_recall: 0.9987 | val_precision: 0.9986\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.35it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 16 | train_loss: 0.0047 | train_acc: 0.9989 | train_F1_score: 0.9986 | train_recall: 0.9987 | train_precision: 0.9987 | val_loss: 0.0065 | val_acc: 0.9986 | val_F1_score: 0.9983 | val_recall: 0.9985 | val_precision: 0.9986\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.30it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 17 | train_loss: 0.0053 | train_acc: 0.9989 | train_F1_score: 0.9986 | train_recall: 0.9989 | train_precision: 0.9988 | val_loss: 0.0068 | val_acc: 0.9987 | val_F1_score: 0.9983 | val_recall: 0.9985 | val_precision: 0.9985\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.27it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 18 | train_loss: 0.0037 | train_acc: 0.9991 | train_F1_score: 0.9988 | train_recall: 0.9990 | train_precision: 0.9989 | val_loss: 0.0058 | val_acc: 0.9990 | val_F1_score: 0.9988 | val_recall: 0.9989 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.15it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 19 | train_loss: 0.0038 | train_acc: 0.9991 | train_F1_score: 0.9988 | train_recall: 0.9991 | train_precision: 0.9989 | val_loss: 0.0080 | val_acc: 0.9982 | val_F1_score: 0.9979 | val_recall: 0.9982 | val_precision: 0.9982\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 20 | train_loss: 0.0029 | train_acc: 0.9992 | train_F1_score: 0.9991 | train_recall: 0.9992 | train_precision: 0.9992 | val_loss: 0.0049 | val_acc: 0.9989 | val_F1_score: 0.9987 | val_recall: 0.9988 | val_precision: 0.9989\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.22it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 21 | train_loss: 0.0027 | train_acc: 0.9994 | train_F1_score: 0.9992 | train_recall: 0.9994 | train_precision: 0.9993 | val_loss: 0.0066 | val_acc: 0.9987 | val_F1_score: 0.9982 | val_recall: 0.9984 | val_precision: 0.9984\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.29it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 22 | train_loss: 0.0032 | train_acc: 0.9993 | train_F1_score: 0.9991 | train_recall: 0.9993 | train_precision: 0.9992 | val_loss: 0.0041 | val_acc: 0.9993 | val_F1_score: 0.9991 | val_recall: 0.9992 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.42it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 23 | train_loss: 0.0021 | train_acc: 0.9995 | train_F1_score: 0.9992 | train_recall: 0.9993 | train_precision: 0.9993 | val_loss: 0.0062 | val_acc: 0.9989 | val_F1_score: 0.9987 | val_recall: 0.9989 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 24 | train_loss: 0.0037 | train_acc: 0.9992 | train_F1_score: 0.9990 | train_recall: 0.9991 | train_precision: 0.9991 | val_loss: 0.0109 | val_acc: 0.9980 | val_F1_score: 0.9975 | val_recall: 0.9979 | val_precision: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.27it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 25 | train_loss: 0.0025 | train_acc: 0.9994 | train_F1_score: 0.9993 | train_recall: 0.9994 | train_precision: 0.9993 | val_loss: 0.0071 | val_acc: 0.9983 | val_F1_score: 0.9978 | val_recall: 0.9982 | val_precision: 0.9979\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.24it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 27 | train_loss: 0.0023 | train_acc: 0.9995 | train_F1_score: 0.9993 | train_recall: 0.9994 | train_precision: 0.9993 | val_loss: 0.0060 | val_acc: 0.9987 | val_F1_score: 0.9985 | val_recall: 0.9986 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.28it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 28 | train_loss: 0.0027 | train_acc: 0.9993 | train_F1_score: 0.9992 | train_recall: 0.9993 | train_precision: 0.9993 | val_loss: 0.0042 | val_acc: 0.9992 | val_F1_score: 0.9991 | val_recall: 0.9992 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 29 | train_loss: 0.0022 | train_acc: 0.9995 | train_F1_score: 0.9993 | train_recall: 0.9994 | train_precision: 0.9994 | val_loss: 0.0064 | val_acc: 0.9986 | val_F1_score: 0.9981 | val_recall: 0.9983 | val_precision: 0.9984\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.54it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 30 | train_loss: 0.0018 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0032 | val_acc: 0.9993 | val_F1_score: 0.9992 | val_recall: 0.9993 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.34it/s]\n311it [00:20, 15.44it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 31 | train_loss: 0.0023 | train_acc: 0.9995 | train_F1_score: 0.9994 | train_recall: 0.9996 | train_precision: 0.9994 | val_loss: 0.0058 | val_acc: 0.9989 | val_F1_score: 0.9989 | val_recall: 0.9990 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.35it/s]\n311it [00:20, 15.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 32 | train_loss: 0.0017 | train_acc: 0.9996 | train_F1_score: 0.9996 | train_recall: 0.9996 | train_precision: 0.9997 | val_loss: 0.0056 | val_acc: 0.9989 | val_F1_score: 0.9988 | val_recall: 0.9990 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"1243it [04:47,  4.32it/s]\n311it [00:20, 15.09it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 33 | train_loss: 0.0018 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9995 | train_precision: 0.9995 | val_loss: 0.0046 | val_acc: 0.9991 | val_F1_score: 0.9989 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 34 | train_loss: 0.0011 | train_acc: 0.9997 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0079 | val_acc: 0.9986 | val_F1_score: 0.9983 | val_recall: 0.9984 | val_precision: 0.9986\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.18it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 35 | train_loss: 0.0018 | train_acc: 0.9996 | train_F1_score: 0.9994 | train_recall: 0.9995 | train_precision: 0.9994 | val_loss: 0.0064 | val_acc: 0.9987 | val_F1_score: 0.9980 | val_recall: 0.9982 | val_precision: 0.9982\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 36 | train_loss: 0.0029 | train_acc: 0.9994 | train_F1_score: 0.9993 | train_recall: 0.9994 | train_precision: 0.9993 | val_loss: 0.0055 | val_acc: 0.9989 | val_F1_score: 0.9987 | val_recall: 0.9988 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.32it/s]\n311it [00:20, 15.16it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 37 | train_loss: 0.0010 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0039 | val_acc: 0.9991 | val_F1_score: 0.9988 | val_recall: 0.9990 | val_precision: 0.9989\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.15it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 38 | train_loss: 0.0015 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0048 | val_acc: 0.9991 | val_F1_score: 0.9989 | val_recall: 0.9990 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.20it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 39 | train_loss: 0.0019 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9995 | val_loss: 0.0038 | val_acc: 0.9993 | val_F1_score: 0.9991 | val_recall: 0.9992 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.23it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 40 | train_loss: 0.0016 | train_acc: 0.9997 | train_F1_score: 0.9996 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0070 | val_acc: 0.9987 | val_F1_score: 0.9985 | val_recall: 0.9986 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.23it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 41 | train_loss: 0.0017 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9995 | val_loss: 0.0059 | val_acc: 0.9988 | val_F1_score: 0.9985 | val_recall: 0.9987 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.06it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 42 | train_loss: 0.0006 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0050 | val_acc: 0.9991 | val_F1_score: 0.9989 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.11it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 43 | train_loss: 0.0019 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0060 | val_acc: 0.9988 | val_F1_score: 0.9983 | val_recall: 0.9985 | val_precision: 0.9984\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.09it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 44 | train_loss: 0.0017 | train_acc: 0.9996 | train_F1_score: 0.9996 | train_recall: 0.9997 | train_precision: 0.9996 | val_loss: 0.0052 | val_acc: 0.9990 | val_F1_score: 0.9990 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.09it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 45 | train_loss: 0.0007 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0063 | val_acc: 0.9988 | val_F1_score: 0.9985 | val_recall: 0.9986 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.12it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 46 | train_loss: 0.0017 | train_acc: 0.9997 | train_F1_score: 0.9996 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0048 | val_acc: 0.9991 | val_F1_score: 0.9988 | val_recall: 0.9989 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 47 | train_loss: 0.0011 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0059 | val_acc: 0.9989 | val_F1_score: 0.9986 | val_recall: 0.9987 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 48 | train_loss: 0.0017 | train_acc: 0.9997 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0067 | val_acc: 0.9988 | val_F1_score: 0.9982 | val_recall: 0.9984 | val_precision: 0.9985\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.10it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 49 | train_loss: 0.0007 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0040 | val_acc: 0.9993 | val_F1_score: 0.9993 | val_recall: 0.9995 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.16it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 50 | train_loss: 0.0001 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0042 | val_acc: 0.9993 | val_F1_score: 0.9992 | val_recall: 0.9992 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 51 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0047 | val_acc: 0.9992 | val_F1_score: 0.9990 | val_recall: 0.9990 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:49,  4.30it/s]\n311it [00:20, 15.20it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 52 | train_loss: 0.0016 | train_acc: 0.9997 | train_F1_score: 0.9996 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0110 | val_acc: 0.9978 | val_F1_score: 0.9968 | val_recall: 0.9972 | val_precision: 0.9971\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.19it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 53 | train_loss: 0.0022 | train_acc: 0.9995 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9995 | val_loss: 0.0057 | val_acc: 0.9990 | val_F1_score: 0.9989 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.22it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 54 | train_loss: 0.0007 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0069 | val_acc: 0.9988 | val_F1_score: 0.9984 | val_recall: 0.9987 | val_precision: 0.9985\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.22it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 55 | train_loss: 0.0014 | train_acc: 0.9997 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0061 | val_acc: 0.9990 | val_F1_score: 0.9988 | val_recall: 0.9989 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.21it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 56 | train_loss: 0.0008 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0051 | val_acc: 0.9993 | val_F1_score: 0.9991 | val_recall: 0.9992 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.29it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 57 | train_loss: 0.0011 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0060 | val_acc: 0.9990 | val_F1_score: 0.9988 | val_recall: 0.9989 | val_precision: 0.9989\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 58 | train_loss: 0.0014 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0058 | val_acc: 0.9989 | val_F1_score: 0.9986 | val_recall: 0.9988 | val_precision: 0.9986\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 59 | train_loss: 0.0010 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9998 | val_loss: 0.0062 | val_acc: 0.9989 | val_F1_score: 0.9987 | val_recall: 0.9989 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 60 | train_loss: 0.0011 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0064 | val_acc: 0.9991 | val_F1_score: 0.9990 | val_recall: 0.9992 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.24it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 61 | train_loss: 0.0008 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0044 | val_acc: 0.9993 | val_F1_score: 0.9990 | val_recall: 0.9992 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 62 | train_loss: 0.0010 | train_acc: 0.9997 | train_F1_score: 0.9996 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0060 | val_acc: 0.9992 | val_F1_score: 0.9989 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 63 | train_loss: 0.0021 | train_acc: 0.9996 | train_F1_score: 0.9996 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0045 | val_acc: 0.9991 | val_F1_score: 0.9990 | val_recall: 0.9991 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 64 | train_loss: 0.0002 | train_acc: 1.0000 | train_F1_score: 0.9999 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0039 | val_acc: 0.9993 | val_F1_score: 0.9993 | val_recall: 0.9994 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"1243it [04:47,  4.32it/s]\n311it [00:20, 15.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 65 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0041 | val_acc: 0.9994 | val_F1_score: 0.9992 | val_recall: 0.9993 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.24it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 66 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0040 | val_acc: 0.9994 | val_F1_score: 0.9993 | val_recall: 0.9995 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.40it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 67 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0042 | val_acc: 0.9994 | val_F1_score: 0.9994 | val_recall: 0.9994 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 68 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0042 | val_acc: 0.9994 | val_F1_score: 0.9991 | val_recall: 0.9992 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.30it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 69 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0042 | val_acc: 0.9994 | val_F1_score: 0.9994 | val_recall: 0.9994 | val_precision: 0.9995\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 70 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0043 | val_acc: 0.9994 | val_F1_score: 0.9994 | val_recall: 0.9995 | val_precision: 0.9994\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.25it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 71 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0044 | val_acc: 0.9994 | val_F1_score: 0.9995 | val_recall: 0.9996 | val_precision: 0.9995\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.33it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 72 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0044 | val_acc: 0.9994 | val_F1_score: 0.9994 | val_recall: 0.9995 | val_precision: 0.9995\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 14.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 73 | train_loss: 0.0000 | train_acc: 1.0000 | train_F1_score: 1.0000 | train_recall: 1.0000 | train_precision: 1.0000 | val_loss: 0.0046 | val_acc: 0.9994 | val_F1_score: 0.9992 | val_recall: 0.9993 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.33it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 74 | train_loss: 0.0028 | train_acc: 0.9995 | train_F1_score: 0.9993 | train_recall: 0.9994 | train_precision: 0.9993 | val_loss: 0.0059 | val_acc: 0.9988 | val_F1_score: 0.9985 | val_recall: 0.9986 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.35it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 75 | train_loss: 0.0013 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0073 | val_acc: 0.9986 | val_F1_score: 0.9984 | val_recall: 0.9985 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.07it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 76 | train_loss: 0.0006 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0062 | val_acc: 0.9989 | val_F1_score: 0.9986 | val_recall: 0.9988 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:48,  4.31it/s]\n311it [00:20, 15.42it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 77 | train_loss: 0.0008 | train_acc: 0.9998 | train_F1_score: 0.9996 | train_recall: 0.9996 | train_precision: 0.9996 | val_loss: 0.0057 | val_acc: 0.9990 | val_F1_score: 0.9989 | val_recall: 0.9990 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.42it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 78 | train_loss: 0.0013 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9998 | train_precision: 0.9997 | val_loss: 0.0033 | val_acc: 0.9994 | val_F1_score: 0.9992 | val_recall: 0.9994 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.37it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 79 | train_loss: 0.0006 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9998 | val_loss: 0.0029 | val_acc: 0.9994 | val_F1_score: 0.9992 | val_recall: 0.9993 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:46,  4.33it/s]\n311it [00:20, 15.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 80 | train_loss: 0.0010 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0043 | val_acc: 0.9992 | val_F1_score: 0.9989 | val_recall: 0.9991 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 81 | train_loss: 0.0004 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0031 | val_acc: 0.9993 | val_F1_score: 0.9992 | val_recall: 0.9994 | val_precision: 0.9993\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 82 | train_loss: 0.0020 | train_acc: 0.9996 | train_F1_score: 0.9995 | train_recall: 0.9996 | train_precision: 0.9995 | val_loss: 0.0061 | val_acc: 0.9987 | val_F1_score: 0.9985 | val_recall: 0.9986 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"1243it [04:47,  4.33it/s]\n311it [00:20, 15.30it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 83 | train_loss: 0.0007 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9998 | val_loss: 0.0050 | val_acc: 0.9992 | val_F1_score: 0.9991 | val_recall: 0.9991 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.44it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 84 | train_loss: 0.0008 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9998 | val_loss: 0.0045 | val_acc: 0.9991 | val_F1_score: 0.9991 | val_recall: 0.9993 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.39it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 85 | train_loss: 0.0009 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9997 | train_precision: 0.9997 | val_loss: 0.0039 | val_acc: 0.9992 | val_F1_score: 0.9990 | val_recall: 0.9991 | val_precision: 0.9992\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.32it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 86 | train_loss: 0.0006 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9999 | train_precision: 0.9998 | val_loss: 0.0095 | val_acc: 0.9986 | val_F1_score: 0.9985 | val_recall: 0.9987 | val_precision: 0.9987\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 87 | train_loss: 0.0008 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0058 | val_acc: 0.9990 | val_F1_score: 0.9987 | val_recall: 0.9989 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 88 | train_loss: 0.0004 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0093 | val_acc: 0.9984 | val_F1_score: 0.9977 | val_recall: 0.9981 | val_precision: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.47it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 89 | train_loss: 0.0008 | train_acc: 0.9999 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0063 | val_acc: 0.9990 | val_F1_score: 0.9988 | val_recall: 0.9989 | val_precision: 0.9989\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.44it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 90 | train_loss: 0.0006 | train_acc: 0.9999 | train_F1_score: 0.9999 | train_recall: 0.9999 | train_precision: 0.9999 | val_loss: 0.0052 | val_acc: 0.9992 | val_F1_score: 0.9990 | val_recall: 0.9992 | val_precision: 0.9991\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.33it/s]\n311it [00:20, 15.36it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 91 | train_loss: 0.0009 | train_acc: 0.9998 | train_F1_score: 0.9997 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0068 | val_acc: 0.9989 | val_F1_score: 0.9988 | val_recall: 0.9990 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 92 | train_loss: 0.0014 | train_acc: 0.9997 | train_F1_score: 0.9996 | train_recall: 0.9997 | train_precision: 0.9996 | val_loss: 0.0061 | val_acc: 0.9989 | val_F1_score: 0.9986 | val_recall: 0.9987 | val_precision: 0.9988\n","output_type":"stream"},{"name":"stderr","text":"\n1243it [04:47,  4.32it/s]\n311it [00:20, 15.36it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 93 | train_loss: 0.0008 | train_acc: 0.9998 | train_F1_score: 0.9998 | train_recall: 0.9998 | train_precision: 0.9998 | val_loss: 0.0045 | val_acc: 0.9992 | val_F1_score: 0.9990 | val_recall: 0.9992 | val_precision: 0.9990\n","output_type":"stream"},{"name":"stderr","text":"\n817it [03:08,  4.31it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# Save Model\ntorch.save(\n        obj=model.state_dict(),\n        f=f\"/kaggle/working/128_epochs.pth\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T17:52:36.099537Z","iopub.status.idle":"2023-12-27T17:52:36.099888Z","shell.execute_reply.started":"2023-12-27T17:52:36.099721Z","shell.execute_reply":"2023-12-27T17:52:36.099738Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}