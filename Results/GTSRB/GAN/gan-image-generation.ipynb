{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":191501,"sourceType":"datasetVersion","datasetId":82373},{"sourceId":7099050,"sourceType":"datasetVersion","datasetId":4091962}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport matplotlib.image as implt\nimport pandas as pd\nimport  glob\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:02:26.627931Z","iopub.execute_input":"2023-12-09T19:02:26.628367Z","iopub.status.idle":"2023-12-09T19:02:26.635716Z","shell.execute_reply.started":"2023-12-09T19:02:26.628331Z","shell.execute_reply":"2023-12-09T19:02:26.634671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.rmdir('.virtual_documents') ","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:18.095274Z","iopub.execute_input":"2023-12-02T16:25:18.095728Z","iopub.status.idle":"2023-12-02T16:25:18.100390Z","shell.execute_reply.started":"2023-12-02T16:25:18.095699Z","shell.execute_reply":"2023-12-02T16:25:18.099325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    '''\n    Generator Class\n    Values:\n        z_dim: the dimension of the noise vector, a scalar\n        im_chan: the number of channels of the output image, a scalar\n              (MNIST is black-and-white, so 1 channel is your default)\n        hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, input_dim=171, im_chan=3, hidden_dim=64):\n        super(Generator, self).__init__()\n        self.input_dim = input_dim\n        # Build the neural network\n        self.gen = nn.Sequential(\n            self.make_gen_block(input_dim, hidden_dim * 4),\n            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n            self.make_gen_block(hidden_dim * 2, hidden_dim),\n            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n        )\n\n    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n        '''\n        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n        Parameters:\n            input_channels: how many channels the input feature representation has\n            output_channels: how many channels the output feature representation should have\n            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n            stride: the stride of the convolution\n            final_layer: a boolean, true if it is the final layer and false otherwise \n                      (affects activation and batchnorm)\n        '''\n        if not final_layer:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.ReLU(inplace=True),\n            )\n        else:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.Tanh(),\n            )\n\n    def forward(self, noise):\n        '''\n        Function for completing a forward pass of the generator: Given a noise tensor,\n        returns generated images.\n        Parameters:\n            noise: a noise tensor with dimensions (n_samples, z_dim)\n        '''\n        x = noise.view(len(noise), self.input_dim, 1, 1)\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:18.101707Z","iopub.execute_input":"2023-12-02T16:25:18.101984Z","iopub.status.idle":"2023-12-02T16:25:18.115135Z","shell.execute_reply.started":"2023-12-02T16:25:18.101960Z","shell.execute_reply":"2023-12-02T16:25:18.114262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_one_hot_labels(labels, n_classes=43):\n    return F.one_hot(labels, n_classes)\n\ndef combine_vectors(x, y):\n    return torch.cat((x.float(), y.float()), 1)\n\ndef get_input_dimensions(z_dim, img_shape=(3, 64, 64), n_classes=43):\n    gen_input_dim = z_dim + n_classes\n    disc_input_dim = img_shape[0] + n_classes\n    \n    return gen_input_dim, disc_input_dim\n\ndef get_noise(n_samples, z_dim, device='cpu'):\n    '''\n    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n    creates a tensor of that shape filled with random numbers from the normal distribution.\n    Parameters:\n      n_samples: the number of samples to generate, a scalar\n      z_dim: the dimension of the noise vector, a scalar\n      device: the device type\n    '''\n    return torch.randn(n_samples, z_dim, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:18.116648Z","iopub.execute_input":"2023-12-02T16:25:18.116982Z","iopub.status.idle":"2023-12-02T16:25:18.127882Z","shell.execute_reply.started":"2023-12-02T16:25:18.116958Z","shell.execute_reply":"2023-12-02T16:25:18.126984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z_dim = 128\ngen_in_dim, _ = get_input_dimensions(z_dim)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:18.549779Z","iopub.execute_input":"2023-12-02T16:25:18.550579Z","iopub.status.idle":"2023-12-02T16:25:18.554974Z","shell.execute_reply.started":"2023-12-02T16:25:18.550535Z","shell.execute_reply":"2023-12-02T16:25:18.553937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device='cuda'\ngen = Generator(input_dim=gen_in_dim).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:18.863965Z","iopub.execute_input":"2023-12-02T16:25:18.864723Z","iopub.status.idle":"2023-12-02T16:25:22.117001Z","shell.execute_reply.started":"2023-12-02T16:25:18.864688Z","shell.execute_reply":"2023-12-02T16:25:22.115901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_tensor_images(image_tensor, num_images=25, size=(1, 64, 64)):\n    '''\n    Function for visualizing images: Given a tensor of images, number of images, and\n    size per image, plots and prints the images in an uniform grid.\n    '''\n    image_tensor = (image_tensor + 1) / 2\n    image_unflat = image_tensor.detach().cpu()\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()\n    \ndef make_grad_hook():\n    '''\n    Function to keep track of gradients for visualization purposes, \n    which fills the grads list when using model.apply(grad_hook).\n    '''\n    grads = []\n    def grad_hook(m):\n        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n            grads.append(m.weight.grad)\n    return grads, grad_hook\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:22.118852Z","iopub.execute_input":"2023-12-02T16:25:22.119185Z","iopub.status.idle":"2023-12-02T16:25:22.127260Z","shell.execute_reply.started":"2023-12-02T16:25:22.119157Z","shell.execute_reply":"2023-12-02T16:25:22.126215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = { 0:'Speed limit (20km/h)', \n            1:'Speed limit (30km/h)', \n            2:'Speed limit (50km/h)', \n            3:'Speed limit (60km/h)', \n            4:'Speed limit (70km/h)', \n            5:'Speed limit (80km/h)', \n            6:'End of speed limit (80km/h)', \n            7:'Speed limit (100km/h)', \n            8:'Speed limit (120km/h)', \n            9:'No passing', \n            10:'No passing veh over 3.5 tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Veh > 3.5 tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End no passing veh > 3.5 tons' }","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:24.997294Z","iopub.execute_input":"2023-12-02T16:25:24.998261Z","iopub.status.idle":"2023-12-02T16:25:25.006791Z","shell.execute_reply.started":"2023-12-02T16:25:24.998224Z","shell.execute_reply":"2023-12-02T16:25:25.005800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_weights = torch.load('/kaggle/input/gan-model/generator.pth')\ngen.load_state_dict(gen_weights)\ngen.eval()\ncount = 1500*43\n\nlabels=[]\nfor i in range(43):\n    labels += [i]*1500\n\n\ntest_noise = get_noise(count, z_dim, device)\ntest_label = torch.tensor(labels)\ntest_OH_label = get_one_hot_labels(test_label.to(device))\ntest_noise_and_label = combine_vectors(test_noise, test_OH_label)\ntest_image_fake = gen(test_noise_and_label)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:33.489804Z","iopub.execute_input":"2023-12-02T16:25:33.490630Z","iopub.status.idle":"2023-12-02T16:25:39.320158Z","shell.execute_reply.started":"2023-12-02T16:25:33.490566Z","shell.execute_reply":"2023-12-02T16:25:39.319131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in classes.values():\n    os.mkdir(i.replace('/',''))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:39.321993Z","iopub.execute_input":"2023-12-02T16:25:39.322275Z","iopub.status.idle":"2023-12-02T16:25:39.328402Z","shell.execute_reply.started":"2023-12-02T16:25:39.322250Z","shell.execute_reply":"2023-12-02T16:25:39.327261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index,i in enumerate(test_image_fake):\n    numpy_image = i.to('cpu').detach().numpy()\n    numpy_image = (np.moveaxis(numpy_image, 0,-1)*128 + 128).astype(np.uint8)\n    plt.imsave(os.path.join('/kaggle/working/',classes[index//1500].replace('/',''),str(index%1500)) + '.jpg', numpy_image)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:25:41.908884Z","iopub.execute_input":"2023-12-02T16:25:41.909254Z","iopub.status.idle":"2023-12-02T16:26:20.588759Z","shell.execute_reply.started":"2023-12-02T16:25:41.909224Z","shell.execute_reply":"2023-12-02T16:26:20.587979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for className in os.listdir('/kaggle/input/gtsrb-german-traffic-sign/Train'):\n    classPath = os.path.join('/kaggle/input/gtsrb-german-traffic-sign/Train',className)\n    for index, imageName in enumerate(os.listdir(classPath)):\n        img = implt.imread(os.path.join(classPath, imageName))\n        outputPath = os.path.join('/kaggle/working/', classes[int(className)].replace('/',''), str(1500+index)) + '.jpg'\n        plt.imsave(outputPath, img)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:26:20.590467Z","iopub.execute_input":"2023-12-02T16:26:20.591107Z","iopub.status.idle":"2023-12-02T16:29:15.018687Z","shell.execute_reply.started":"2023-12-02T16:26:20.591073Z","shell.execute_reply":"2023-12-02T16:29:15.017854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, imageName in enumerate(os.listdir('/kaggle/input/gtsrb-german-traffic-sign/Test')):\n    if imageName == 'GT-final_test.csv':\n        continue\n    try:\n        imagePath = os.path.join('/kaggle/input/gtsrb-german-traffic-sign/Test', imageName)\n        img = implt.imread(imagePath)\n        classId = (test_df[test_df[\"Path\"] == 'Test/' + imageName]['ClassId']).iloc[0]\n        outputPath = os.path.join('/kaggle/working/', classes[classId].replace('/',''), str(1860+index)) + '.jpg'\n        plt.imsave(outputPath, img)\n    except:\n        print('Error:')\n        print(imageName)\n        print(imagePath)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:38:02.070371Z","iopub.execute_input":"2023-12-02T16:38:02.071442Z","iopub.status.idle":"2023-12-02T16:39:40.115668Z","shell.execute_reply.started":"2023-12-02T16:38:02.071403Z","shell.execute_reply":"2023-12-02T16:39:40.114701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/generated_images', 'zip', '/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:57:23.060087Z","iopub.execute_input":"2023-12-02T16:57:23.060476Z","iopub.status.idle":"2023-12-02T16:57:23.423047Z","shell.execute_reply.started":"2023-12-02T16:57:23.060446Z","shell.execute_reply":"2023-12-02T16:57:23.422200Z"},"trusted":true},"execution_count":null,"outputs":[]}]}